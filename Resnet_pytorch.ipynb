{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MaJu502/proyectoDL/blob/main/Resnet_pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Proyecto Deep Learning\n",
        "- Diego Cordova 20212\n",
        "- Marco Jurado 20308\n",
        "- Cristian Aguirre 20231\n",
        "- Paola Contreras 20213\n",
        "- Paola de Leon 20361"
      ],
      "metadata": {
        "id": "dgU-QqmJU3ZV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Carga de Dataset"
      ],
      "metadata": {
        "id": "f-bUhYK_LJ5o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown 1BoNWFSXxtN74PgLcBxfGWyeKUOfevQEP"
      ],
      "metadata": {
        "id": "Lod5bJutyRzl",
        "outputId": "45d4c2b6-9187-4f6c-d858-2d748a6e760c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1BoNWFSXxtN74PgLcBxfGWyeKUOfevQEP\n",
            "To: /content/kaggle.json\n",
            "\r  0% 0.00/64.0 [00:00<?, ?B/s]\r100% 64.0/64.0 [00:00<00:00, 234kB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "gT95QfnIUwXF",
        "outputId": "7653fe1f-d8ae-4966-9e3e-2bc391b78ec8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (1.5.16)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle) (1.16.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from kaggle) (2023.7.22)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kaggle) (4.66.1)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle) (8.0.1)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.0.7)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle) (6.1.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle) (0.5.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.4)\n"
          ]
        }
      ],
      "source": [
        "! pip install kaggle"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -a /root/"
      ],
      "metadata": {
        "id": "DGDK03s94jb4",
        "outputId": "ca734fb8-859c-47b9-ff32-82250ec13acd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ".   .bashrc  .config   .jupyter  .launchpadlib\t.npm\t  .tmux.conf\n",
            "..  .cache   .ipython  .keras\t .local\t\t.profile  .wget-hsts\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir /root/.kaggle/"
      ],
      "metadata": {
        "id": "7vR3i-e72KwA"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mv /content/kaggle.json /root/.kaggle/\n"
      ],
      "metadata": {
        "id": "maN5xtpp2aXZ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ls /root/.kaggle/\n"
      ],
      "metadata": {
        "id": "hGjouUlh2R15",
        "outputId": "73eae0a9-021e-4ca9-d7df-0cf64b717543",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "kaggle.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!chmod 600 /root/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "c7fOtUl25da6"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d jonathanoheix/face-expression-recognition-dataset"
      ],
      "metadata": {
        "id": "zNYGBDhq5Rpb",
        "outputId": "ee068185-2ab8-432b-a93d-f334290d2c1e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading face-expression-recognition-dataset.zip to /content\n",
            " 92% 111M/121M [00:01<00:00, 127MB/s] \n",
            "100% 121M/121M [00:01<00:00, 112MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content\n",
        "!unzip -q face-expression-recognition-dataset.zip"
      ],
      "metadata": {
        "id": "E_hBnXDQANGJ",
        "outputId": "2f5e0e0c-c9f1-4d61-b30f-c144b323a838",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modelo"
      ],
      "metadata": {
        "id": "3RjamWOoxPnL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "# Ruta de la carpeta que deseas eliminar\n",
        "folder_path = './images/train/disgust'\n",
        "\n",
        "# Elimina todas las imágenes en la carpeta\n",
        "for file_name in os.listdir(folder_path):\n",
        "    file_path = os.path.join(folder_path, file_name)\n",
        "    try:\n",
        "        if os.path.isfile(file_path) or os.path.islink(file_path):\n",
        "            os.unlink(file_path)\n",
        "        elif os.path.isdir(file_path):\n",
        "            shutil.rmtree(file_path)\n",
        "    except Exception as e:\n",
        "        print(f'Error al eliminar {file_path}: {e}')\n",
        "\n",
        "# Elimina la carpeta misma\n",
        "try:\n",
        "    os.rmdir(folder_path)\n",
        "except Exception as e:\n",
        "    print(f'Error al eliminar la carpeta {folder_path}: {e}')\n"
      ],
      "metadata": {
        "id": "q0d4_grHk-m-"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ruta de la carpeta que deseas eliminar\n",
        "folder_path = './images/validation/disgust'\n",
        "\n",
        "# Elimina todas las imágenes en la carpeta\n",
        "for file_name in os.listdir(folder_path):\n",
        "    file_path = os.path.join(folder_path, file_name)\n",
        "    try:\n",
        "        if os.path.isfile(file_path) or os.path.islink(file_path):\n",
        "            os.unlink(file_path)\n",
        "        elif os.path.isdir(file_path):\n",
        "            shutil.rmtree(file_path)\n",
        "    except Exception as e:\n",
        "        print(f'Error al eliminar {file_path}: {e}')\n",
        "\n",
        "# Elimina la carpeta misma\n",
        "try:\n",
        "    os.rmdir(folder_path)\n",
        "except Exception as e:\n",
        "    print(f'Error al eliminar la carpeta {folder_path}: {e}')"
      ],
      "metadata": {
        "id": "YRak5SVjsVOf"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "import shutil\n",
        "\n",
        "# Ruta de la carpeta que deseas modificar\n",
        "folder_path = './images/train/happy'\n",
        "\n",
        "# Lista de archivos en la carpeta\n",
        "file_list = os.listdir(folder_path)\n",
        "\n",
        "# Número de imágenes que deseas eliminar\n",
        "num_images_to_delete = 3000\n",
        "\n",
        "# Verifica si hay suficientes imágenes para eliminar\n",
        "if len(file_list) < num_images_to_delete:\n",
        "    print(f'No hay suficientes imágenes en {folder_path} para eliminar.')\n",
        "else:\n",
        "    # Selecciona aleatoriamente las imágenes que se eliminarán\n",
        "    images_to_delete = random.sample(file_list, num_images_to_delete)\n",
        "\n",
        "    # Elimina las imágenes seleccionadas\n",
        "    for file_name in images_to_delete:\n",
        "        file_path = os.path.join(folder_path, file_name)\n",
        "        try:\n",
        "            if os.path.isfile(file_path):\n",
        "                os.unlink(file_path)\n",
        "            elif os.path.isdir(file_path):\n",
        "                shutil.rmtree(file_path)\n",
        "        except Exception as e:\n",
        "            print(f'Error al eliminar {file_path}: {e}')\n",
        "\n",
        "    print(f'Se han eliminado {num_images_to_delete} imágenes de {folder_path}.')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OeuMTV5av9QL",
        "outputId": "2507089a-fff6-4a2b-f00d-be9fe4e10be4"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Se han eliminado 3000 imágenes de ./images/train/happy.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "# Directorio raíz que contiene subdirectorios para cada emoción\n",
        "root_dir = './images/train/'\n",
        "\n",
        "# Lista de emociones\n",
        "emotions = ['angry', 'fear', 'happy', 'neutral', 'sad', 'surprise']\n",
        "\n",
        "# Inicializa un diccionario para almacenar shapes únicos por emoción\n",
        "unique_shapes_by_emotion = {emotion: [] for emotion in emotions}\n",
        "\n",
        "# Itera a través de las carpetas de emociones\n",
        "for emotion in emotions:\n",
        "    emotion_dir = os.path.join(root_dir, emotion)\n",
        "    image_files = os.listdir(emotion_dir)\n",
        "\n",
        "    # Itera a través de los archivos de imágenes en cada carpeta de emoción\n",
        "    for image_file in image_files:\n",
        "        image_path = os.path.join(emotion_dir, image_file)\n",
        "        image = cv2.imread(image_path)\n",
        "        shape = image.shape\n",
        "        if shape not in unique_shapes_by_emotion[emotion]:\n",
        "            unique_shapes_by_emotion[emotion].append(shape)\n",
        "\n",
        "# Imprime los shapes únicos por emoción\n",
        "for emotion, shapes in unique_shapes_by_emotion.items():\n",
        "    print(f\"Shapes únicos para la emoción '{emotion}':\")\n",
        "    for shape in shapes:\n",
        "        print(shape)\n"
      ],
      "metadata": {
        "id": "M-eAUshpzJ4c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "04078cb9-9618-411c-cf39-6ced44b8322e"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shapes únicos para la emoción 'angry':\n",
            "(48, 48, 3)\n",
            "Shapes únicos para la emoción 'fear':\n",
            "(48, 48, 3)\n",
            "Shapes únicos para la emoción 'happy':\n",
            "(48, 48, 3)\n",
            "Shapes únicos para la emoción 'neutral':\n",
            "(48, 48, 3)\n",
            "Shapes únicos para la emoción 'sad':\n",
            "(48, 48, 3)\n",
            "Shapes únicos para la emoción 'surprise':\n",
            "(48, 48, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loader para el Modelo"
      ],
      "metadata": {
        "id": "xvQrlBeFa4dT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torchvision import datasets, transforms\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torchvision import transforms as T\n",
        "\n",
        "batch_size = 128\n",
        "base_path = \"./images/\"\n",
        "\n",
        "train_augs = T.Compose([T.RandomHorizontalFlip(p = 0.5),T.RandomRotation(degrees = (-20,+20)),T.ToTensor()])\n",
        "#To tensor in pytorch converts image from numpy or PIL into pytorch tensors also it will convert (h,w,c)->(c,h,w)\n",
        "valid_augs = T.Compose([T.ToTensor()])\n",
        "\n",
        "\n",
        "# Crear conjuntos de datos\n",
        "train_dataset = ImageFolder(base_path + \"train\", transform =train_augs)\n",
        "validation_dataset = ImageFolder(base_path + \"validation\", transform =valid_augs)\n",
        "\n",
        "# Crear generadores de lotes (DataLoaders)\n",
        "trainloader = torch.utils.data.DataLoader(train_dataset,batch_size=batch_size,shuffle = True)\n",
        "validloader = torch.utils.data.DataLoader(validation_dataset,batch_size=batch_size)"
      ],
      "metadata": {
        "id": "XVgcJVpGL4vT"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Se preparan los datos para CUDA"
      ],
      "metadata": {
        "id": "S1PXnUjREYzE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Entreno del Modelo"
      ],
      "metadata": {
        "id": "aBGw_p2tcf6z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scikit-learn"
      ],
      "metadata": {
        "id": "4eQiBBnMsvKA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install timm"
      ],
      "metadata": {
        "id": "8TmJK4FQRuf2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import timm\n",
        "from torch import nn\n",
        "\n",
        "class FaceModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(FaceModel,self).__init__()\n",
        "        self.eff_net = timm.create_model('resnet34',pretrained = True,num_classes = 7)\n",
        "    def forward(self,images,labels = None):\n",
        "        logits = self.eff_net(images)\n",
        "        if labels != None:\n",
        "            loss = nn.CrossEntropyLoss()(logits,labels)\n",
        "            return logits,loss\n",
        "        return logits\n",
        "\n",
        "modelo = FaceModel()"
      ],
      "metadata": {
        "id": "UJKEZKlSMUHs"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = ('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Computation device: {device}\\n\")\n",
        "modelo = modelo.to(device)\n",
        "\n",
        "device_in_model = 'cpu' if False in [i.is_cuda for i in modelo.parameters()] else 'cuda'\n",
        "print('model using', device_in_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kLbCJsysRavi",
        "outputId": "0beef6df-2e5e-4e34-89f2-e74091b50e99"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Computation device: cuda\n",
            "\n",
            "model using cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def multiclass_accuracy(y_pred,y_true):\n",
        "    top_p,top_class = y_pred.topk(1,dim = 1)\n",
        "    equals = top_class == y_true.view(*top_class.shape)\n",
        "    return torch.mean(equals.type(torch.FloatTensor))"
      ],
      "metadata": {
        "id": "JHT_7XOGVMLQ"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "65aqImLaV51m"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epoch = 20\n",
        "\n",
        "\n",
        "def train_fn(model,dataloader,optimizer,current_epo):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "    total_acc = 0.0\n",
        "    tk = tqdm(dataloader,desc = \"EPOCHS\" + \"[TRAIN]\" + str(current_epo+1) + \"/\"+ str(epoch))\n",
        "    for t,data in enumerate(tk):\n",
        "        images,labels = data\n",
        "        images,labels = images.to(device),labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        logits,loss = model(images,labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "        total_acc += multiclass_accuracy(logits,labels)\n",
        "        tk.set_postfix({'loss':'%6f' %float(total_loss/(t+1)),'acc':'%6f' %float(total_acc/(t+1))})\n",
        "    return total_loss/len(dataloader),total_acc/len(dataloader)\n",
        "\n"
      ],
      "metadata": {
        "id": "6mWaSSEYVzys"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def eval_fn(model,dataloader,current_epo):\n",
        "    model.eval()\n",
        "    total_loss = 0.0\n",
        "    total_acc = 0.0\n",
        "    tk = tqdm(dataloader,desc = \"EPOCH\" + \"[VALID]\" + str(current_epo + 1) + \"/\"+ str(epoch))\n",
        "    for t,data in enumerate(tk):\n",
        "        images,labels = data\n",
        "        images,labels = images.to(device),labels.to(device)\n",
        "\n",
        "\n",
        "        logits,loss = model(images,labels)\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        total_acc += multiclass_accuracy(logits,labels)\n",
        "        tk.set_postfix({'loss':'%6f' %float(total_loss/(t+1)),'acc':'%6f' %float(total_acc/(t+1))})\n",
        "    return total_loss/len(dataloader),total_acc/len(dataloader)\n",
        "\n"
      ],
      "metadata": {
        "id": "paOB5s84V1L5"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.Adam(modelo.parameters(),lr = 0.0001)"
      ],
      "metadata": {
        "id": "49Il8IwdV8YD"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_valid_loss= np.inf\n",
        "for i in range(epoch):\n",
        "    train_loss,train_acc = train_fn(modelo,trainloader,optimizer,i)\n",
        "    eval_loss,eval_acc = eval_fn(modelo,validloader,i)\n",
        "    if eval_loss < best_valid_loss:\n",
        "        torch.save(modelo.state_dict(),'best-weights.pt')\n",
        "        print(\"Saved Best Valid Loss\")\n",
        "        best_valid_loss = eval_loss"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tfa_iwXmWAaV",
        "outputId": "009d6bdf-7eda-4e1f-a779-e51d407e3c39"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "EPOCHS[TRAIN]1/20: 100%|██████████| 175/175 [00:23<00:00,  7.34it/s, loss=1.532643, acc=0.367484]\n",
            "EPOCH[VALID]1/20: 100%|██████████| 55/55 [00:03<00:00, 16.21it/s, loss=1.748013, acc=0.297648]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved Best Valid Loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "EPOCHS[TRAIN]2/20: 100%|██████████| 175/175 [00:22<00:00,  7.78it/s, loss=1.481146, acc=0.393698]\n",
            "EPOCH[VALID]2/20: 100%|██████████| 55/55 [00:03<00:00, 15.60it/s, loss=1.687636, acc=0.330589]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved Best Valid Loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "EPOCHS[TRAIN]3/20: 100%|██████████| 175/175 [00:22<00:00,  7.77it/s, loss=1.437043, acc=0.408439]\n",
            "EPOCH[VALID]3/20: 100%|██████████| 55/55 [00:03<00:00, 16.04it/s, loss=1.632620, acc=0.354311]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved Best Valid Loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "EPOCHS[TRAIN]4/20: 100%|██████████| 175/175 [00:24<00:00,  7.15it/s, loss=1.399324, acc=0.428014]\n",
            "EPOCH[VALID]4/20: 100%|██████████| 55/55 [00:04<00:00, 12.67it/s, loss=1.579671, acc=0.384567]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved Best Valid Loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "EPOCHS[TRAIN]5/20: 100%|██████████| 175/175 [00:22<00:00,  7.65it/s, loss=1.369719, acc=0.441814]\n",
            "EPOCH[VALID]5/20: 100%|██████████| 55/55 [00:03<00:00, 16.04it/s, loss=1.518344, acc=0.419506]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved Best Valid Loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "EPOCHS[TRAIN]6/20: 100%|██████████| 175/175 [00:22<00:00,  7.90it/s, loss=1.335447, acc=0.458490]\n",
            "EPOCH[VALID]6/20: 100%|██████████| 55/55 [00:03<00:00, 13.92it/s, loss=1.472594, acc=0.440959]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved Best Valid Loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "EPOCHS[TRAIN]7/20: 100%|██████████| 175/175 [00:21<00:00,  8.02it/s, loss=1.312070, acc=0.464555]\n",
            "EPOCH[VALID]7/20: 100%|██████████| 55/55 [00:04<00:00, 13.09it/s, loss=1.476191, acc=0.440810]\n",
            "EPOCHS[TRAIN]8/20: 100%|██████████| 175/175 [00:22<00:00,  7.94it/s, loss=1.282429, acc=0.484701]\n",
            "EPOCH[VALID]8/20: 100%|██████████| 55/55 [00:03<00:00, 15.28it/s, loss=1.453871, acc=0.456864]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved Best Valid Loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "EPOCHS[TRAIN]9/20: 100%|██████████| 175/175 [00:22<00:00,  7.75it/s, loss=1.253102, acc=0.494977]\n",
            "EPOCH[VALID]9/20: 100%|██████████| 55/55 [00:03<00:00, 16.23it/s, loss=1.397889, acc=0.473758]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved Best Valid Loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "EPOCHS[TRAIN]10/20: 100%|██████████| 175/175 [00:22<00:00,  7.69it/s, loss=1.224041, acc=0.512112]\n",
            "EPOCH[VALID]10/20: 100%|██████████| 55/55 [00:03<00:00, 16.59it/s, loss=1.359776, acc=0.488544]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved Best Valid Loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "EPOCHS[TRAIN]11/20: 100%|██████████| 175/175 [00:22<00:00,  7.75it/s, loss=1.204852, acc=0.520251]\n",
            "EPOCH[VALID]11/20: 100%|██████████| 55/55 [00:03<00:00, 16.05it/s, loss=1.371117, acc=0.495636]\n",
            "EPOCHS[TRAIN]12/20: 100%|██████████| 175/175 [00:22<00:00,  7.81it/s, loss=1.189249, acc=0.523909]\n",
            "EPOCH[VALID]12/20: 100%|██████████| 55/55 [00:03<00:00, 14.05it/s, loss=1.339552, acc=0.510270]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved Best Valid Loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "EPOCHS[TRAIN]13/20: 100%|██████████| 175/175 [00:21<00:00,  7.97it/s, loss=1.165769, acc=0.535650]\n",
            "EPOCH[VALID]13/20: 100%|██████████| 55/55 [00:04<00:00, 12.82it/s, loss=1.343823, acc=0.504873]\n",
            "EPOCHS[TRAIN]14/20: 100%|██████████| 175/175 [00:21<00:00,  7.97it/s, loss=1.145978, acc=0.546153]\n",
            "EPOCH[VALID]14/20: 100%|██████████| 55/55 [00:03<00:00, 14.85it/s, loss=1.337704, acc=0.510125]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved Best Valid Loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "EPOCHS[TRAIN]15/20: 100%|██████████| 175/175 [00:22<00:00,  7.66it/s, loss=1.121583, acc=0.555436]\n",
            "EPOCH[VALID]15/20: 100%|██████████| 55/55 [00:03<00:00, 16.14it/s, loss=1.295005, acc=0.526741]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved Best Valid Loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "EPOCHS[TRAIN]16/20: 100%|██████████| 175/175 [00:23<00:00,  7.30it/s, loss=1.108104, acc=0.559742]\n",
            "EPOCH[VALID]16/20: 100%|██████████| 55/55 [00:03<00:00, 14.92it/s, loss=1.257842, acc=0.533718]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved Best Valid Loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "EPOCHS[TRAIN]17/20: 100%|██████████| 175/175 [00:22<00:00,  7.70it/s, loss=1.093020, acc=0.566820]\n",
            "EPOCH[VALID]17/20: 100%|██████████| 55/55 [00:03<00:00, 16.13it/s, loss=1.260967, acc=0.535838]\n",
            "EPOCHS[TRAIN]18/20: 100%|██████████| 175/175 [00:22<00:00,  7.76it/s, loss=1.071320, acc=0.579081]\n",
            "EPOCH[VALID]18/20: 100%|██████████| 55/55 [00:03<00:00, 15.47it/s, loss=1.272239, acc=0.536407]\n",
            "EPOCHS[TRAIN]19/20: 100%|██████████| 175/175 [00:22<00:00,  7.88it/s, loss=1.052537, acc=0.583552]\n",
            "EPOCH[VALID]19/20: 100%|██████████| 55/55 [00:04<00:00, 13.14it/s, loss=1.251940, acc=0.542809]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved Best Valid Loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "EPOCHS[TRAIN]20/20: 100%|██████████| 175/175 [00:22<00:00,  7.94it/s, loss=1.034291, acc=0.594948]\n",
            "EPOCH[VALID]20/20: 100%|██████████| 55/55 [00:03<00:00, 13.81it/s, loss=1.264448, acc=0.541091]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "model_filename = \"model.pkl\"\n",
        "\n",
        "with open(model_filename, 'wb') as model_file:\n",
        "    pickle.dump(modelo, model_file)\n"
      ],
      "metadata": {
        "id": "hqoncgFQXC_d"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_results(history):\n",
        "    acc = history.history['accuracy']\n",
        "    val_acc = history.history['val_accuracy']\n",
        "    loss = history.history['loss']\n",
        "    val_loss = history.history['val_loss']\n",
        "\n",
        "    epochs = range(1, len(acc) + 1)\n",
        "\n",
        "    plt.figure(figsize = (24, 6))\n",
        "    plt.subplot(1,2,1)\n",
        "    plt.plot(epochs, acc, 'b', label = 'Training Accuracy')\n",
        "    plt.plot(epochs, val_acc, 'r', label = 'Validation Accuracy')\n",
        "    plt.grid(True)\n",
        "    plt.legend()\n",
        "    plt.xlabel('Epoch')\n",
        "\n",
        "\n",
        "\n",
        "    plt.subplot(1,2,2)\n",
        "    plt.plot(epochs, loss, 'b', label = 'Training Loss')\n",
        "    plt.plot(epochs, val_loss, 'r', label = 'Validation Loss')\n",
        "    plt.grid(True)\n",
        "    plt.legend()\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.show()\n",
        "\n",
        "def get_best_epcoh(history):\n",
        "    valid_acc = history.history['val_accuracy']\n",
        "    best_epoch = valid_acc.index(max(valid_acc)) + 1\n",
        "    best_acc =  max(valid_acc)\n",
        "    print('Best Validation Accuracy Score {:0.5f}, is for epoch {}'.format( best_acc, best_epoch))\n",
        "    return best_epoch"
      ],
      "metadata": {
        "id": "FxgZJ2mcZd2f"
      },
      "execution_count": 51,
      "outputs": []
    }
  ]
}
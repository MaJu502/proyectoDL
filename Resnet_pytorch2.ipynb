{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MaJu502/proyectoDL/blob/main/Resnet_pytorch2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Proyecto Deep Learning\n",
        "- Diego Cordova 20212\n",
        "- Marco Jurado 20308\n",
        "- Cristian Aguirre 20231\n",
        "- Paola Contreras 20213\n",
        "- Paola de Leon 20361"
      ],
      "metadata": {
        "id": "dgU-QqmJU3ZV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Carga de Dataset"
      ],
      "metadata": {
        "id": "f-bUhYK_LJ5o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown 1BoNWFSXxtN74PgLcBxfGWyeKUOfevQEP"
      ],
      "metadata": {
        "id": "Lod5bJutyRzl",
        "outputId": "2fe39553-5e37-4901-bc5a-72eed06aeeef",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1BoNWFSXxtN74PgLcBxfGWyeKUOfevQEP\n",
            "To: /content/kaggle.json\n",
            "\r  0% 0.00/64.0 [00:00<?, ?B/s]\r100% 64.0/64.0 [00:00<00:00, 365kB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown"
      ],
      "metadata": {
        "id": "AHXQIhRP6Hp_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db42794d-1b05-4d31-df08-f8b80471c95a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "usage: gdown [-h] [-V] [-O OUTPUT] [-q] [--fuzzy] [--id] [--proxy PROXY] [--speed SPEED]\n",
            "             [--no-cookies] [--no-check-certificate] [--continue] [--folder] [--remaining-ok]\n",
            "             url_or_id\n",
            "gdown: error: the following arguments are required: url_or_id\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "gT95QfnIUwXF",
        "outputId": "017d4ddf-7cae-4493-f229-6b2415f9070a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (1.5.16)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle) (1.16.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from kaggle) (2023.7.22)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kaggle) (4.66.1)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle) (8.0.1)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.0.7)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle) (6.1.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle) (0.5.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.4)\n"
          ]
        }
      ],
      "source": [
        "! pip install kaggle"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -a /root/"
      ],
      "metadata": {
        "id": "DGDK03s94jb4",
        "outputId": "f56f6f1b-4ed0-44f7-c524-d0daedcbfe1d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ".   .bashrc  .config   .jupyter  .keras\t\t.local\t.nv\t  .tmux.conf\n",
            "..  .cache   .ipython  .kaggle\t .launchpadlib\t.npm\t.profile  .wget-hsts\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir /root/.kaggle/"
      ],
      "metadata": {
        "id": "7vR3i-e72KwA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36827ebc-dc73-4c55-de79-254e90b98eff"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘/root/.kaggle/’: File exists\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mv /content/kaggle.json /root/.kaggle/\n"
      ],
      "metadata": {
        "id": "maN5xtpp2aXZ"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ls /root/.kaggle/\n"
      ],
      "metadata": {
        "id": "hGjouUlh2R15",
        "outputId": "1989fae6-8200-48ad-d575-aa0b76040409",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "kaggle.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!chmod 600 /root/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "c7fOtUl25da6"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d jonathanoheix/face-expression-recognition-dataset"
      ],
      "metadata": {
        "id": "zNYGBDhq5Rpb",
        "outputId": "9da4d142-aca6-4bb0-9b33-f1a71f6e2dcf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "face-expression-recognition-dataset.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content\n",
        "!unzip -q face-expression-recognition-dataset.zip"
      ],
      "metadata": {
        "id": "E_hBnXDQANGJ",
        "outputId": "142f77bb-ce90-4c3d-9ac0-2e27f027dd33",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "replace images/images/train/angry/0.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modelo"
      ],
      "metadata": {
        "id": "3RjamWOoxPnL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "# Ruta de la carpeta que deseas eliminar\n",
        "folder_path = './images/train/disgust'\n",
        "\n",
        "# Elimina todas las imágenes en la carpeta\n",
        "for file_name in os.listdir(folder_path):\n",
        "    file_path = os.path.join(folder_path, file_name)\n",
        "    try:\n",
        "        if os.path.isfile(file_path) or os.path.islink(file_path):\n",
        "            os.unlink(file_path)\n",
        "        elif os.path.isdir(file_path):\n",
        "            shutil.rmtree(file_path)\n",
        "    except Exception as e:\n",
        "        print(f'Error al eliminar {file_path}: {e}')\n",
        "\n",
        "# Elimina la carpeta misma\n",
        "try:\n",
        "    os.rmdir(folder_path)\n",
        "except Exception as e:\n",
        "    print(f'Error al eliminar la carpeta {folder_path}: {e}')\n"
      ],
      "metadata": {
        "id": "q0d4_grHk-m-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "8f80fcd5-357f-4a8a-c3f3-0317121727bb"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-94b9a7ddd7cb>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Elimina todas las imágenes en la carpeta\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mfile_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mfile_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './images/train/disgust'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ruta de la carpeta que deseas eliminar\n",
        "folder_path = './images/validation/disgust'\n",
        "\n",
        "# Elimina todas las imágenes en la carpeta\n",
        "for file_name in os.listdir(folder_path):\n",
        "    file_path = os.path.join(folder_path, file_name)\n",
        "    try:\n",
        "        if os.path.isfile(file_path) or os.path.islink(file_path):\n",
        "            os.unlink(file_path)\n",
        "        elif os.path.isdir(file_path):\n",
        "            shutil.rmtree(file_path)\n",
        "    except Exception as e:\n",
        "        print(f'Error al eliminar {file_path}: {e}')\n",
        "\n",
        "# Elimina la carpeta misma\n",
        "try:\n",
        "    os.rmdir(folder_path)\n",
        "except Exception as e:\n",
        "    print(f'Error al eliminar la carpeta {folder_path}: {e}')"
      ],
      "metadata": {
        "id": "YRak5SVjsVOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "import shutil\n",
        "\n",
        "# Ruta de la carpeta que deseas modificar\n",
        "folder_path = './images/train/happy'\n",
        "\n",
        "# Lista de archivos en la carpeta\n",
        "file_list = os.listdir(folder_path)\n",
        "\n",
        "# Número de imágenes que deseas eliminar\n",
        "num_images_to_delete = 3000\n",
        "\n",
        "# Verifica si hay suficientes imágenes para eliminar\n",
        "if len(file_list) < num_images_to_delete:\n",
        "    print(f'No hay suficientes imágenes en {folder_path} para eliminar.')\n",
        "else:\n",
        "    # Selecciona aleatoriamente las imágenes que se eliminarán\n",
        "    images_to_delete = random.sample(file_list, num_images_to_delete)\n",
        "\n",
        "    # Elimina las imágenes seleccionadas\n",
        "    for file_name in images_to_delete:\n",
        "        file_path = os.path.join(folder_path, file_name)\n",
        "        try:\n",
        "            if os.path.isfile(file_path):\n",
        "                os.unlink(file_path)\n",
        "            elif os.path.isdir(file_path):\n",
        "                shutil.rmtree(file_path)\n",
        "        except Exception as e:\n",
        "            print(f'Error al eliminar {file_path}: {e}')\n",
        "\n",
        "    print(f'Se han eliminado {num_images_to_delete} imágenes de {folder_path}.')\n"
      ],
      "metadata": {
        "id": "OeuMTV5av9QL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "72a74f7c-89ec-4e7b-b9b2-ec1800f81f3f"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Se han eliminado 3000 imágenes de ./images/train/happy.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "root_dir = './images/train/'\n",
        "\n",
        "# Lista de emociones\n",
        "emotions = ['angry', 'fear', 'happy', 'neutral', 'sad', 'surprise']\n",
        "unique_shapes_by_emotion = {emotion: [] for emotion in emotions}\n",
        "\n",
        "for emotion in emotions:\n",
        "    emotion_dir = os.path.join(root_dir, emotion)\n",
        "    image_files = os.listdir(emotion_dir)\n",
        "\n",
        "    for image_file in image_files:\n",
        "        image_path = os.path.join(emotion_dir, image_file)\n",
        "        image = cv2.imread(image_path)\n",
        "        shape = image.shape\n",
        "        if shape not in unique_shapes_by_emotion[emotion]:\n",
        "            unique_shapes_by_emotion[emotion].append(shape)\n",
        "\n",
        "for emotion, shapes in unique_shapes_by_emotion.items():\n",
        "    print(f\"Shapes únicos para la emoción '{emotion}':\")\n",
        "    for shape in shapes:\n",
        "        print(shape)\n"
      ],
      "metadata": {
        "id": "M-eAUshpzJ4c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loader para el Modelo"
      ],
      "metadata": {
        "id": "xvQrlBeFa4dT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torchvision import datasets, transforms\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torchvision import transforms as T\n",
        "\n",
        "batch_size = 128\n",
        "base_path = \"./images/\"\n",
        "\n",
        "train_augs = T.Compose([T.RandomHorizontalFlip(p = 0.5),T.RandomRotation(degrees = (-20,+20)),T.ToTensor()])\n",
        "#To tensor in pytorch converts image from numpy or PIL into pytorch tensors also it will convert (h,w,c)->(c,h,w)\n",
        "valid_augs = T.Compose([T.ToTensor()])\n",
        "\n",
        "\n",
        "# Crear conjuntos de datos\n",
        "train_dataset = ImageFolder(base_path + \"train\", transform =train_augs)\n",
        "validation_dataset = ImageFolder(base_path + \"validation\", transform =valid_augs)\n",
        "\n",
        "# Crear generadores de lotes (DataLoaders)\n",
        "trainloader = torch.utils.data.DataLoader(train_dataset,batch_size=batch_size,shuffle = True)\n",
        "validloader = torch.utils.data.DataLoader(validation_dataset,batch_size=batch_size)"
      ],
      "metadata": {
        "id": "XVgcJVpGL4vT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Se preparan los datos para CUDA"
      ],
      "metadata": {
        "id": "S1PXnUjREYzE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Entreno del Modelo"
      ],
      "metadata": {
        "id": "aBGw_p2tcf6z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scikit-learn"
      ],
      "metadata": {
        "id": "4eQiBBnMsvKA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install timm"
      ],
      "metadata": {
        "id": "8TmJK4FQRuf2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import timm\n",
        "from torch import nn\n",
        "\n",
        "class FaceModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(FaceModel,self).__init__()\n",
        "        self.eff_net = timm.create_model('resnet34',pretrained = True,num_classes = 7)\n",
        "    def forward(self,images,labels = None):\n",
        "        logits = self.eff_net(images)\n",
        "        if labels != None:\n",
        "            loss = nn.CrossEntropyLoss()(logits,labels)\n",
        "            return logits,loss\n",
        "        return logits\n",
        "\n",
        "modelo = FaceModel()"
      ],
      "metadata": {
        "id": "UJKEZKlSMUHs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = ('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Computation device: {device}\\n\")\n",
        "modelo = modelo.to(device)\n",
        "\n",
        "device_in_model = 'cpu' if False in [i.is_cuda for i in modelo.parameters()] else 'cuda'\n",
        "print('model using', device_in_model)"
      ],
      "metadata": {
        "id": "kLbCJsysRavi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def multiclass_accuracy(y_pred,y_true):\n",
        "    top_p,top_class = y_pred.topk(1,dim = 1)\n",
        "    equals = top_class == y_true.view(*top_class.shape)\n",
        "    return torch.mean(equals.type(torch.FloatTensor))"
      ],
      "metadata": {
        "id": "JHT_7XOGVMLQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "65aqImLaV51m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epoch = 60\n",
        "\n",
        "\n",
        "def train_fn(model,dataloader,optimizer,current_epo):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "    total_acc = 0.0\n",
        "    tk = tqdm(dataloader,desc = \"EPOCHS\" + \"[TRAIN]\" + str(current_epo+1) + \"/\"+ str(epoch))\n",
        "    for t,data in enumerate(tk):\n",
        "        images,labels = data\n",
        "        images,labels = images.to(device),labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        logits,loss = model(images,labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "        total_acc += multiclass_accuracy(logits,labels)\n",
        "        tk.set_postfix({'loss':'%6f' %float(total_loss/(t+1)),'acc':'%6f' %float(total_acc/(t+1))})\n",
        "    return total_loss/len(dataloader),total_acc/len(dataloader)\n",
        "\n"
      ],
      "metadata": {
        "id": "6mWaSSEYVzys"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "def eval_fn(model, dataloader, current_epo):\n",
        "    model.eval()\n",
        "    total_loss = 0.0\n",
        "    total_acc = 0.0\n",
        "    all_true_labels = []\n",
        "    all_predicted_labels = []\n",
        "\n",
        "    tk = tqdm(dataloader, desc=\"EPOCH\" + \"[VALID]\" + str(current_epo + 1) + \"/\" + str(epoch))\n",
        "\n",
        "    for t, data in enumerate(tk):\n",
        "        images, labels = data\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        logits, loss = model(images, labels)\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        total_acc += multiclass_accuracy(logits, labels)\n",
        "\n",
        "        # Collect true labels and predicted labels\n",
        "        all_true_labels.extend(labels.cpu().numpy())\n",
        "        all_predicted_labels.extend(logits.argmax(1).cpu().numpy())\n",
        "\n",
        "        tk.set_postfix({'loss': '%6f' % float(total_loss / (t + 1)), 'acc': '%6f' % float(total_acc / (t + 1))})\n",
        "\n",
        "    # Calculate and display the confusion matrix\n",
        "    confusion = confusion_matrix(all_true_labels, all_predicted_labels)\n",
        "    sns.heatmap(confusion, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
        "    plt.xlabel(\"Predicted Labels\")\n",
        "    plt.ylabel(\"True Labels\")\n",
        "    plt.show()\n",
        "\n",
        "    return total_loss / len(dataloader), total_acc / len(dataloader)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "paOB5s84V1L5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.Adam(modelo.parameters(),lr = 0.0001)"
      ],
      "metadata": {
        "id": "49Il8IwdV8YD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# best_valid_loss= np.inf\n",
        "# for i in range(epoch):\n",
        "#     train_loss,train_acc = train_fn(modelo,trainloader,optimizer,i)\n",
        "#     eval_loss,eval_acc = eval_fn(modelo,validloader,i)\n",
        "#     if eval_loss < best_valid_loss:\n",
        "#         torch.save(modelo.state_dict(),'best-weights.pt')\n",
        "#         print(\"Saved Best Valid Loss\")\n",
        "#         best_valid_loss = eval_loss"
      ],
      "metadata": {
        "id": "Tfa_iwXmWAaV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import joblib\n",
        "\n",
        "# joblib.dump(modelo, 'modelo.pkl')"
      ],
      "metadata": {
        "id": "hqoncgFQXC_d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "modelo_cargado = joblib.load('modelo.pkl')"
      ],
      "metadata": {
        "id": "7xM0pL5w7ddg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "\n",
        "# Paso 1: Cargar y preprocesar la imagen\n",
        "image_path = \"./images/validation/sad/10004.jpg\"\n",
        "image = Image.open(image_path).convert(\"RGB\")\n",
        "\n",
        "# Añadir transformaciones necesarias, incluyendo normalización\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    # transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "image = transform(image)\n",
        "\n",
        "# Ajusta la dimensión del lote (batch dimension) si es necesario\n",
        "image = image.unsqueeze(0)\n",
        "\n",
        "# Paso 2: Mover el modelo a la CPU y realizar la predicción\n",
        "modelo.to('cpu')  # Mover el modelo a la CPU\n",
        "\n",
        "output = modelo(image)\n",
        "\n",
        "# Para obtener las probabilidades de clase en un problema de clasificación\n",
        "probabilities = torch.nn.functional.softmax(output[0], dim=0)\n",
        "\n",
        "# Paso 3: Interpretar los resultados\n",
        "# Puedes obtener la clase predicha como el índice con mayor probabilidad\n",
        "predicted_class = torch.argmax(probabilities).item()\n",
        "print(f\"La imagen probablemente pertenece a la clase: {predicted_class}\")\n"
      ],
      "metadata": {
        "id": "3GB__CF5Dibm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Mount persons folder"
      ],
      "metadata": {
        "id": "jWZYIfDZ_cVj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "SErVJEX8_g4b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p '/content/persons/'\n",
        "!cp /content/drive/MyDrive/persons/persons.zip /content/persons/"
      ],
      "metadata": {
        "id": "v64e18KG_kDB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/drive/MyDrive/persons/persons.zip -d /content/persons/"
      ],
      "metadata": {
        "id": "E2qEASdV_qxI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm /content/persons/persons.zip"
      ],
      "metadata": {
        "id": "yl3QK6oU_ywM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Predict video frames"
      ],
      "metadata": {
        "id": "SeLGFCsm_5Fa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "folder_path = \"./persons/content/persons/\"\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "class_labels = ['angry', 'fear', 'happy', 'neutral', 'sad', 'surprise']\n",
        "\n",
        "predictions = []\n",
        "probabilities = []\n",
        "\n",
        "for filename in os.listdir(folder_path):\n",
        "    if filename.endswith(\".jpg\"):\n",
        "        image_path = os.path.join(folder_path, filename)\n",
        "        image = Image.open(image_path).convert(\"RGB\")\n",
        "        image = transform(image)\n",
        "        image = image.unsqueeze(0)\n",
        "\n",
        "        # Realizar la predicción\n",
        "        output = modelo(image)\n",
        "        probabilities_batch = torch.nn.functional.softmax(output[0], dim=0)\n",
        "        predicted_class = torch.argmax(probabilities_batch).item()\n",
        "\n",
        "        predictions.append(predicted_class)\n",
        "        probabilities.append(probabilities_batch)\n",
        "\n",
        "# Convertir las listas en tensores\n",
        "predictions = torch.tensor(predictions)\n",
        "probabilities = torch.stack(probabilities)\n",
        "\n",
        "# Calcular la distribución de las clases\n",
        "class_distribution = torch.bincount(predictions, minlength=len(class_labels))\n",
        "\n",
        "# Graficar\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.bar(class_labels, class_distribution)\n",
        "plt.xlabel('Clases')\n",
        "plt.ylabel('Número de Imágenes')\n",
        "plt.title('Distribución de Clases')\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "QptI7440il8h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Código para mover archivos a carpeta\n",
        "\n",
        "# import os\n",
        "# import shutil\n",
        "\n",
        "# source_folder = './'\n",
        "\n",
        "# destination_folder = 'persons/'\n",
        "\n",
        "# if not os.path.exists(destination_folder):\n",
        "#     os.makedirs(destination_folder)\n",
        "\n",
        "# files = os.listdir(source_folder)\n",
        "\n",
        "# for file in files:\n",
        "#     if 'person_' in file:\n",
        "#         source_path = os.path.join(source_folder, file)\n",
        "#         destination_path = os.path.join(destination_folder, file)\n",
        "#         shutil.move(source_path, destination_path)\n"
      ],
      "metadata": {
        "id": "8p7Y1DMQh9fd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ## Código para eliminar archivos en carpeta\n",
        "\n",
        "# import os\n",
        "\n",
        "# directory_path = './persons/content/persons/'\n",
        "# files = os.listdir(directory_path)\n",
        "\n",
        "# for file in files:\n",
        "#       file_path = os.path.join(directory_path, file)\n",
        "#       os.remove(file_path)\n",
        "#       print(f\"Deleted: {file_path}\")\n"
      ],
      "metadata": {
        "id": "Mz2MHoN7ld1k"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
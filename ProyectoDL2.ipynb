{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MaJu502/proyectoDL/blob/main/ProyectoDL2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6bu_uFabK3dJ",
        "outputId": "57c8d22c-cf32-4f49-cb8a-7fccb99e5711"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.8.0.76)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python) (1.23.5)\n"
          ]
        }
      ],
      "source": [
        "!pip install opencv-python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m7NDJCx_uesb",
        "outputId": "238d0c61-d071-43e8-bba4-c8780e5f8e44"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mtcnn\n",
            "  Downloading mtcnn-0.1.1-py3-none-any.whl (2.3 MB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/2.3 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.2/2.3 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.6/2.3 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/2.3 MB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/2.3 MB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m \u001b[32m2.2/2.3 MB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: keras>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from mtcnn) (2.14.0)\n",
            "Requirement already satisfied: opencv-python>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from mtcnn) (4.8.0.76)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python>=4.1.0->mtcnn) (1.23.5)\n",
            "Installing collected packages: mtcnn\n",
            "Successfully installed mtcnn-0.1.1\n"
          ]
        }
      ],
      "source": [
        "!pip install mtcnn\n",
        "#https://medium.com/lcc-unison/aplicaci%C3%B3n-de-reconocimiento-facial-en-tiempo-real-para-identificar-a-alumnos-de-la-licenciatura-en-2e2b53870995"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dQVQMJgoMLjZ"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import torch\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from mtcnn import MTCNN\n",
        "from torchvision.transforms import functional as F"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1bw1sTEYLCqN",
        "outputId": "e020fd6c-4a0f-4eb6-fcaf-8f15a1795ab7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Se han guardado 72 frames del video face_recognition_1.mp4 como imágenes.\n",
            "Se han guardado 41 frames del video face_recognition_2.mp4 como imágenes.\n",
            "Proceso completo.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import cv2\n",
        "\n",
        "# Carpeta que contiene los videos\n",
        "video_folder = 'validation_videos/'\n",
        "\n",
        "# Carpeta de salida para guardar los frames\n",
        "output_folder = 'validation_frames/'\n",
        "\n",
        "# Crea la carpeta de salida si no existe\n",
        "if not os.path.exists(output_folder):\n",
        "    os.makedirs(output_folder)\n",
        "\n",
        "# Lista de archivos en la carpeta de videos\n",
        "video_files = os.listdir(video_folder)\n",
        "\n",
        "for video_file in video_files:\n",
        "    if video_file.endswith('.mp4') or video_file.endswith('.avi'):\n",
        "        video_path = os.path.join(video_folder, video_file)\n",
        "\n",
        "        # Abre el video\n",
        "        cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "        # Verifica si el video se abrió correctamente\n",
        "        if not cap.isOpened():\n",
        "            print(f\"No se pudo abrir el video: {video_path}\")\n",
        "            continue\n",
        "\n",
        "        frame_count = 0\n",
        "        frame_interval = 5  # Captura un frame cada 5 frames\n",
        "\n",
        "        # Lee y guarda los frames como imágenes\n",
        "        while True:\n",
        "            ret, frame = cap.read()\n",
        "\n",
        "            if not ret:\n",
        "                break\n",
        "\n",
        "            if frame_count % frame_interval == 0:\n",
        "                # Guarda el frame como una imagen\n",
        "                frame_filename = os.path.join(output_folder, f'{os.path.splitext(video_file)[0]}_frame_{frame_count:04d}.png')\n",
        "                cv2.imwrite(frame_filename, frame)\n",
        "\n",
        "            frame_count += 1\n",
        "\n",
        "        # Cierra el video\n",
        "        cap.release()\n",
        "\n",
        "        print(f'Se han guardado {frame_count // frame_interval} frames del video {video_file} como imágenes.')\n",
        "\n",
        "print('Proceso completo.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O9YxjPOYK9Xa"
      },
      "outputs": [],
      "source": [
        "# Model YOLO\n",
        "model = torch.hub.load('ultralytics/yolov5', 'yolov5s', pretrained=True)\n",
        "# Model MTCNN\n",
        "face_detector = MTCNN()\n",
        "\n",
        "# Carpeta de salida para guardar resultados\n",
        "output_folder = 'persons/'\n",
        "\n",
        "if not os.path.exists(output_folder):\n",
        "    os.makedirs(output_folder)\n",
        "\n",
        "# Carpeta que contiene los frames de validación\n",
        "folder = 'validation_frames/'  # Cambiar el nombre de la carpeta de frames de validación\n",
        "files = os.listdir(folder)\n",
        "\n",
        "# Listas para métricas\n",
        "true_positives = 0\n",
        "false_positives = 0\n",
        "false_negatives = 0\n",
        "\n",
        "# Evaluar cada elemento dentro de los frames de validación\n",
        "for img_name in files:\n",
        "    img_path = os.path.join(\"validation_frames\", img_name)  # Ruta de la carpeta de validación\n",
        "    img = Image.open(img_path)\n",
        "    results = model(img)\n",
        "\n",
        "    # Obtener resultados de bounding boxes\n",
        "    bboxes = results.pred[0]\n",
        "\n",
        "    # Flag para seguimiento de detecciones\n",
        "    detection_flag = False\n",
        "\n",
        "    for i, bbox in enumerate(bboxes):\n",
        "        # Ver si la clase es de tipo person\n",
        "        if bbox[-1] == 0:\n",
        "            x1, y1, x2, y2 = bbox[0:4].int().tolist()\n",
        "\n",
        "            # Recortar imagen para obtener únicamente la caja\n",
        "            cropped_img = img.crop((x1, y1, x2, y2))\n",
        "\n",
        "            # Recortar caja para obtener únicamente las caras\n",
        "            image_np = np.array(cropped_img)\n",
        "            face_results = face_detector.detect_faces(image_np)\n",
        "\n",
        "            if len(face_results) > 0:\n",
        "                detection_flag = True\n",
        "                face_bbox = face_results[0]['box']\n",
        "                x, y, w, h = face_bbox\n",
        "                face_image = cropped_img.crop((x, y, x + w, y + h))\n",
        "\n",
        "                # Guardar imagen en carpeta persona\n",
        "                output_path = os.path.join(output_folder, f\"person_{os.path.splitext(img_name)[0]}_{i}.jpg\")\n",
        "                face_image.save(output_path)\n",
        "\n",
        "    if detection_flag:\n",
        "        true_positives += 1\n",
        "    else:\n",
        "        false_negatives += 1\n",
        "\n",
        "# Calcular falsos positivos\n",
        "false_positives = len(files) - true_positives\n",
        "\n",
        "# Calcular métricas\n",
        "precision = true_positives / (true_positives + false_positives)\n",
        "recall = true_positives / (true_positives + false_negatives)\n",
        "f1_score = 2 * (precision * recall) / (precision + recall)\n",
        "\n",
        "print(f\"True Positives: {true_positives}\")\n",
        "print(f\"False Positives: {false_positives}\")\n",
        "print(f\"False Negatives: {false_negatives}\")\n",
        "print(f\"Precision: {precision}\")\n",
        "print(f\"Recall: {recall}\")\n",
        "print(f\"F1 Score: {f1_score}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install joblib"
      ],
      "metadata": {
        "id": "mp_PbDERHVoI",
        "outputId": "9590b434-c30a-4139-aede-c77e40e443e6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (1.3.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "\n",
        "# Guardar el modelo YOLO\n",
        "yolo_model_path = 'yolo_model.pkl'\n",
        "joblib.dump(model, yolo_model_path)\n",
        "\n",
        "# Guardar el modelo MTCNN (asegúrate de haber importado MTCNN correctamente)\n",
        "mtcnn_model_path = 'mtcnn_model.pkl'\n",
        "joblib.dump(face_detector, mtcnn_model_path)\n"
      ],
      "metadata": {
        "id": "aEVtu287HaL8",
        "outputId": "b9f54acc-f97d-485e-c59a-af000e5c12db",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['mtcnn_model.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cargar el modelo YOLO\n",
        "loaded_yolo_model = joblib.load(yolo_model_path)\n",
        "\n",
        "# Cargar el modelo MTCNN\n",
        "loaded_mtcnn_model = joblib.load(mtcnn_model_path)\n"
      ],
      "metadata": {
        "id": "PWEr1iSrHimd"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}